{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682333b8-9a35-4c5d-9e3a-5ffa209cce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5848cd5a-58ea-459f-aaa6-ee84a2a8e349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parameters: 431569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torchvision.transforms import Resize\n",
    "import torch\n",
    "from utils.make_dfu import make_dfu\n",
    "from mccullen.vae import ConvVAE\n",
    "\n",
    "vae = ConvVAE(init_channels = 16, # initial number of filters\n",
    "              final_channels = 64,\n",
    "              latent_dim = 64, # latent dimension for sampling\n",
    "              hidden_dim = 128)\n",
    "\n",
    "\n",
    "print('# parameters:',sum([np.prod(m.shape) for n,m in vae.named_parameters()]))\n",
    "vae.load_state_dict(torch.load('models/vae_overfit.pt',map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd752bf1-8cba-4d64-b53e-b964cc726269",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('data/dfu_v2.pkl'):\n",
    "    dfu = pd.read_pickle('data/dfu_v2.pkl')\n",
    "else:\n",
    "    dfu = make_dfu()\n",
    "    dfu.to_pickle('data/dfu_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0cc11e-fcd8-4a1f-8b50-8200d63c064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load (or create) the processed image data for the vae\n",
    "scripts = dfu.script.to_list()\n",
    "\n",
    "if os.path.exists('data/PS_v2_32.pkl'):\n",
    "    with open('data/PS_v2_32.pkl','rb') as f:\n",
    "        PS = pickle.load(f)\n",
    "else:\n",
    "    rs = Resize((32,32))\n",
    "    PS = dfu.apply(lambda D: \n",
    "    (rs(torch.Tensor([D.picture])),D.rep)\n",
    "              ,axis=1).tolist()\n",
    "    with open('data/PS_v2_32.pkl','wb') as f:\n",
    "        pickle.dump(PS,f)\n",
    "\n",
    "\n",
    "PS = [(1-p[0],p[1]) for p in PS]\n",
    "ls = [p[1] for p in PS] # letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "603e8318-fcf4-42eb-a9c1-62fe529e6bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 s, sys: 4.19 s, total: 25.1 s\n",
      "Wall time: 7.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create vectors for all characters\n",
    "bs=256\n",
    "dl = torch.utils.data.DataLoader(dataset=PS, \n",
    "                                 batch_size=bs, \n",
    "                                 shuffle=False)\n",
    "\n",
    "hs=[]\n",
    "for b,q in dl:\n",
    "    h,_,_ = vae.encoder(b)\n",
    "    hs.append(h)\n",
    "    \n",
    "hs = torch.cat(hs).detach().numpy() # \"hidden\" states- vector rep for each character\n",
    "# normalize vectors to length 1 for easy computation of cosine\n",
    "vs = (hs.T/np.sqrt(np.sum(hs**2,axis=1))).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d57c18-d01e-496e-a0ae-e975bf8a0e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ŧ', 0.8736037),\n",
       " ('Ĭ', 0.87193763),\n",
       " ('T', 0.86511827),\n",
       " ('Ī', 0.85592043),\n",
       " ('Ǐ', 0.84747434),\n",
       " ('Ĩ', 0.8457887),\n",
       " ('Ｔ', 0.8435838),\n",
       " ('Ï', 0.83890235),\n",
       " ('Ṫ', 0.82552445),\n",
       " ('ꞁ', 0.82385993)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_matches(im,script):\n",
    "    \"\"\"\n",
    "    returns top matches for image, restricted to a given script\n",
    "    remember to invert the image so that the background is 0.\n",
    "    returns: list of character-cos pairs\n",
    "    \"\"\"\n",
    "    v_script = np.array([v for s,v in zip(scripts,vs) \n",
    "                         if s==script])\n",
    "\n",
    "    ls_script = np.array([l for s,l in zip(scripts,ls) \n",
    "                         if s==script])\n",
    "\n",
    "\n",
    "\n",
    "    rs = Resize((32,32))\n",
    "    im=rs(torch.Tensor([[im]]))\n",
    "    with torch.no_grad():\n",
    "        h,_,_ = vae.encoder(im)\n",
    "\n",
    "    v = h.numpy()[0]\n",
    "    v = v/np.sqrt(np.sum(v**2))\n",
    "\n",
    "    coss = np.inner(v,v_script)\n",
    "\n",
    "    return [(ls_script[k],coss[k]) \n",
    "            for k in np.argsort(-coss)][:10]\n",
    "\n",
    "im = 1-dfu.picture.iloc[808]\n",
    "top_matches(im,'LATIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818fb868-a080-4f15-8b52-b4ba1386f864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
